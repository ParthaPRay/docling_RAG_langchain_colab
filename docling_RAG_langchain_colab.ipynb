{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Docling RAG with Langchain on Colab\n",
        "\n",
        "Partha Pratim Ray, https://github.com/ParthaPRay"
      ],
      "metadata": {
        "id": "20M0YM2XuHA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://ds4sd.github.io/docling/examples/rag_langchain/"
      ],
      "metadata": {
        "id": "_kIz60vMaXjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requirements for this example:\n",
        "%pip install -qq docling docling-core python-dotenv langchain-text-splitters langchain-huggingface langchain-milvus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVAEkM9iaUQ8",
        "outputId": "40ef4915-039f-49f0-da3b-775d1797517a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.2/543.2 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6AeAkqeaHS5",
        "outputId": "45db524c-24ac-488e-8894-3a5926da2aad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# For local machine only\n",
        "# import os\n",
        "\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# load_dotenv()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab only\n",
        "\n",
        "# Firstly, Save \"HF_TOKEN\" HuggingFace TOKEN into Colab Secrets\n",
        "\n",
        "# Then with Notebook Access\n",
        "\n",
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aNQkov90amjT",
        "outputId": "614cc061-c37e-4481-b4f6-228005459d5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loader and Splitter"
      ],
      "metadata": {
        "id": "Fn6zN9c5ayVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterator\n",
        "\n",
        "from langchain_core.document_loaders import BaseLoader\n",
        "from langchain_core.documents import Document as LCDocument\n",
        "\n",
        "from docling.document_converter import DocumentConverter\n",
        "\n",
        "class DoclingPDFLoader(BaseLoader):\n",
        "\n",
        "    def __init__(self, file_path: str | list[str]) -> None:\n",
        "        self._file_paths = file_path if isinstance(file_path, list) else [file_path]\n",
        "        self._converter = DocumentConverter()\n",
        "\n",
        "    def lazy_load(self) -> Iterator[LCDocument]:\n",
        "        for source in self._file_paths:\n",
        "            dl_doc = self._converter.convert(source).document\n",
        "\n",
        "            #text = dl_doc.export_to_markdown() # Markdown\n",
        "\n",
        "            text = dl_doc.export_to_markdown(strict_text=True)  # Text\n",
        "\n",
        "            #text = dl_doc.export_to_document_tokens() # Doctags\n",
        "\n",
        "            ############ JSON\n",
        "            #import json\n",
        "            #text = json.dumps(dl_doc.export_to_dict()) # JSON\n",
        "\n",
        "            ########### YAML\n",
        "            #import yaml\n",
        "            #text = yaml.safe_dump(dl_doc.document.export_to_dict())  #YAML\n",
        "\n",
        "            yield LCDocument(page_content=text)"
      ],
      "metadata": {
        "id": "HVZGSFKkavz7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document Path\n",
        "\n",
        "Single or Multiple Documents"
      ],
      "metadata": {
        "id": "FRVydrZjg_Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = [\"https://arxiv.org/pdf/2408.09869\",\"https://raw.githubusercontent.com/DS4SD/docling/main/tests/data/2206.01062.pdf\"]  # Docling Technical Report"
      ],
      "metadata": {
        "id": "v9_UpaMya32I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Splitter\n",
        "\n",
        "CHange Chunk suze and chunk overlap"
      ],
      "metadata": {
        "id": "RGVDvnbjhDPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = DoclingPDFLoader(file_path=FILE_PATH)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")"
      ],
      "metadata": {
        "id": "xxCKPOVWa-nk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Splitting"
      ],
      "metadata": {
        "id": "_amrU8P1hH6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "-DCXlqzfbCEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9664683-d4e0-4ca5-932d-527cdccc01ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings from HuggingFace Models"
      ],
      "metadata": {
        "id": "ObU1j56fbK-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "HF_EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID)"
      ],
      "metadata": {
        "id": "MjGmdFpBbL2f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Store Milvus from Langchain"
      ],
      "metadata": {
        "id": "3oNZr9IvboGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "MILVUS_URI = os.environ.get(\n",
        "    \"MILVUS_URI\", f\"{(tmp_dir := TemporaryDirectory()).name}/milvus_demo.db\"\n",
        ")\n",
        "\n",
        "vectorstore = Milvus.from_documents(\n",
        "    splits,\n",
        "    embeddings,\n",
        "    connection_args={\"uri\": MILVUS_URI},\n",
        "    drop_old=True,\n",
        ")"
      ],
      "metadata": {
        "id": "vTn_1vuIbpGP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM from HuggingFace Models"
      ],
      "metadata": {
        "id": "t1cNle2rbtdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "### Use Locally\n",
        "# HF_API_KEY = os.environ.get(\"HF_TOKEN\")\n",
        "\n",
        "##### For colab only\n",
        "from google.colab import userdata\n",
        "HF_API_KEY=userdata.get('HF_TOKEN')\n",
        "#######\n",
        "\n",
        "HF_LLM_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=HF_LLM_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "4cpodi0obuDN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG Implementation"
      ],
      "metadata": {
        "id": "b4Vs5PM6cWxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterable\n",
        "\n",
        "from langchain_core.documents import Document as LCDocument\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def format_docs(docs: Iterable[LCDocument]):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {question}\\nAnswer:\\n\"\n",
        ")\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "5wLakfkGcXN-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question to RAG Based on the Document"
      ],
      "metadata": {
        "id": "AM-ZStIDhYue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Does Docling implements a linear pipeline of operations?\") # Docling paper first pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "sPZqQoENcags",
        "outputId": "7541773e-ce32-4da8-c32d-b395d29d35f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, Docling implements a linear pipeline of operations, where each operation executes sequentially on a given document. The pipeline consists of the following stages: document parsing, standard model pipeline, and output assembly. Each stage performs specific tasks on the document and passes the result to the next stage. The standard model pipeline can be customized by sub-classing from an abstract base class or cloning the default model pipeline, allowing for extension of the capabilities of Docling.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"How many pages were human annotated for DocLayNet?\") #Docling paper second pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "tQJUxSRoiEJ7",
        "outputId": "9d9c89cc-5a96-4e61-8b94-563929e153ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The number of pages that were human annotated for DocLayNet is not explicitly stated in the provided context, but it can be inferred that the dataset contains 80863 unique document pages. Among these, there are 7059 pages with two instances of human annotations, and 1591 pages with three. This amounts to a total of 91104 annotation instances, which implies that a fraction of the pages have been human annotated. However, the exact number of pages that have been human annotated cannot be determined with certainty from the provided context.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "duJKROTIjcfI"
      }
    }
  ]
}